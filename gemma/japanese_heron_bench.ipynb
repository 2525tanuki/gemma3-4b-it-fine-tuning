{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa78d6f6fdc74e2b8d8b8362192fc8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b6232b6e0994e15a56e04d4b453753b",
              "IPY_MODEL_4dd8e8773a934e17966a43608dd37255",
              "IPY_MODEL_4a731ae8ae104a509202384da55025b2"
            ],
            "layout": "IPY_MODEL_af399a4fa93b40498987441dd38bdc07"
          }
        },
        "5b6232b6e0994e15a56e04d4b453753b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48531e2ec10545098f78d495b5c83d90",
            "placeholder": "​",
            "style": "IPY_MODEL_bdc517f4fc604627a31115793e4fdcee",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4dd8e8773a934e17966a43608dd37255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d8a56a64f9848d59bc2965c68d01c78",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26ee24c8c0354223bf3ac09dcc9cb95c",
            "value": 2
          }
        },
        "4a731ae8ae104a509202384da55025b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e1a655a50f4ffe96da88900bfff2b4",
            "placeholder": "​",
            "style": "IPY_MODEL_91260905cd6e4a32bcb481acd6a31f08",
            "value": " 2/2 [00:03&lt;00:00,  1.67s/it]"
          }
        },
        "af399a4fa93b40498987441dd38bdc07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48531e2ec10545098f78d495b5c83d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc517f4fc604627a31115793e4fdcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d8a56a64f9848d59bc2965c68d01c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ee24c8c0354223bf3ac09dcc9cb95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60e1a655a50f4ffe96da88900bfff2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91260905cd6e4a32bcb481acd6a31f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install fugashi\n",
        "!pip install emoji\n",
        "!pip install rouge_score\n",
        "!pip install unidic-lite # for MeCab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLqNkFm8Qj_m",
        "outputId": "ca9f5b6c-a00c-4e12-8da7-664561a2d7d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Requirement already satisfied: unidic-lite in /usr/local/lib/python3.11/dist-packages (1.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import emoji\n",
        "from PIL import Image\n",
        "from transformers import AutoModelForImageTextToText, AutoProcessor\n",
        "import torch\n",
        "from typing import Callable\n",
        "import abc\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from datasets import Dataset, load_dataset\n",
        "from concurrent.futures import ProcessPoolExecutor, Future\n",
        "from fugashi import Tagger\n",
        "from rouge_score import rouge_scorer, scoring\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "_0uHhztIPNq-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"HUGGING_FACE_TOKEN\"] = userdata.get(\"HUGGING_FACE_TOKEN\")"
      ],
      "metadata": {
        "id": "1IqejBY3Qt-E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=os.environ[\"HUGGING_FACE_TOKEN\"])"
      ],
      "metadata": {
        "id": "3uGTTo0VQuSI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class TaskConfig:\n",
        "    max_dataset_len: int | None = None\n",
        "    rotate_choices: bool = False\n",
        "\n",
        "\n",
        "class Task(abc.ABC):\n",
        "    def __init__(self, config: TaskConfig):\n",
        "        self.config = config\n",
        "\n",
        "        if self.config.max_dataset_len is not None:\n",
        "            self.dataset = self._prepare_dataset().select(\n",
        "                range(self.config.max_dataset_len)\n",
        "            )\n",
        "        else:\n",
        "            self.dataset = self._prepare_dataset()\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _prepare_dataset(self) -> Dataset:\n",
        "        \"\"\"Prepares the dataset.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def doc_to_text(self, doc) -> str:\n",
        "        \"\"\"Converts a document to text.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def doc_to_visual(self, doc) -> list[Image.Image]:\n",
        "        \"\"\"Converts a document to visual.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def doc_to_id(self, doc) -> str:\n",
        "        \"\"\"Converts a document to id.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def doc_to_answer(self, doc) -> str:\n",
        "        \"\"\"Converts a document to answer.\"\"\"\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "xfNkMQnFF2iz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JapaneseHeronBench(Task):\n",
        "    default_metric = \"heron-bench\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _prepare_dataset() -> Dataset:\n",
        "        ds = load_dataset(\"Silviase/Japanese-Heron-Bench\", split=\"train\")\n",
        "        ds = ds.rename_column(\"text\", \"input_text\")\n",
        "        return ds\n",
        "\n",
        "    @staticmethod\n",
        "    def doc_to_text(doc) -> str:\n",
        "        return doc[\"input_text\"]\n",
        "\n",
        "    @staticmethod\n",
        "    def doc_to_visual(doc) -> list[Image.Image]:\n",
        "        return [doc[\"image\"]]\n",
        "\n",
        "    @staticmethod\n",
        "    def doc_to_id(doc) -> str:\n",
        "        return str(doc[\"question_id\"])\n",
        "\n",
        "    @staticmethod\n",
        "    def doc_to_answer(doc) -> str:\n",
        "        return doc[\"answer\"][\"gpt-4-0125-preview\"]"
      ],
      "metadata": {
        "id": "HHX7wxlBQ6tJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TaskRegistry:\n",
        "    \"\"\"Registry to map metrics to their corresponding scorer classes.\"\"\"\n",
        "\n",
        "    _tasks: dict[str, Callable[[TaskConfig], Task]] = {\n",
        "        \"japanese-heron-bench\": JapaneseHeronBench,\n",
        "    }\n",
        "    @classmethod\n",
        "    def get_task_list(cls):\n",
        "        return list(cls._tasks.keys())\n",
        "\n",
        "    @classmethod\n",
        "    def load_task(cls, task_name: str, task_config: TaskConfig = TaskConfig()) -> Task:\n",
        "        try:\n",
        "            return cls._tasks[task_name](task_config)  # type: ignore\n",
        "        except KeyError:\n",
        "            raise ValueError(f\"Task '{task_name}' is not supported.\")"
      ],
      "metadata": {
        "id": "LZmy7J42RMm-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class AggregateOutput:\n",
        "    overall_score: float\n",
        "    details: dict[str, float]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ScorerConfig:\n",
        "    docs: dict | None = None\n",
        "    judge_model: str | None = None\n",
        "    batch_size: int = 10\n",
        "    random_choice: bool = False\n",
        "\n",
        "\n",
        "class Scorer(ABC):\n",
        "    def __init__(self, config: ScorerConfig):\n",
        "        self.config = config\n",
        "\n",
        "    @abstractmethod\n",
        "    def score(self, refs: list[str], preds: list[str]) -> list:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def aggregate(self, scores: list) -> AggregateOutput:\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "xB4tVkHCRZSJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MecabTokenizer:\n",
        "    def __init__(self) -> None:\n",
        "        self.tagger = Tagger(\"-Owakati\")\n",
        "\n",
        "    def normalize_answer(self, text: str) -> str:\n",
        "        \"\"\"Lower case text, remove punctuation and extra whitespace, etc.\"\"\"\n",
        "\n",
        "        def white_space_fix(text: str) -> str:\n",
        "            return \" \".join(text.split())\n",
        "\n",
        "        def remove_emoji(text: str) -> str:\n",
        "            text = \"\".join([\"\" if emoji.is_emoji(c) else c for c in text])\n",
        "            emoji_pattern = re.compile(\n",
        "                \"[\"\n",
        "                \"\\U0001f600-\\U0001f64f\"  # emoticons\n",
        "                \"\\U0001f300-\\U0001f5ff\"  # symbols & pictographs\n",
        "                \"\\U0001f680-\\U0001f6ff\"  # transport & map symbols\n",
        "                \"\\U0001f1e0-\\U0001f1ff\"  # flags (iOS)\n",
        "                \"\\U00002702-\\U000027b0\"\n",
        "                \"]+\",\n",
        "                flags=re.UNICODE,\n",
        "            )\n",
        "            return emoji_pattern.sub(r\"\", text)\n",
        "\n",
        "        text = remove_emoji(text)\n",
        "        # see neologdn docs for details, but handles things like full/half width variation\n",
        "        # text = neologdn.normalize(text) FIXME: fix c++12 error when installing neologdn\n",
        "        text = unicodedata.normalize(\"NFKC\", text)\n",
        "        text = white_space_fix(text)\n",
        "        return text\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return self.tagger.parse(self.normalize_answer(text)).split()\n",
        "\n",
        "def rouge_ja(refs: list[str], preds: list[str]) -> dict:\n",
        "    \"\"\"Compute ROUGE-L scores for Japanese text.\n",
        "    Args:\n",
        "        refs: list of reference strings\n",
        "        preds: list of predicted strings\n",
        "    Returns:\n",
        "        dict: dictionary with keys: { 'rouge1', 'rouge2', 'rougeL' }\n",
        "        Each value is a float representing the ROUGE score (f-measure) * 100.\n",
        "    \"\"\"\n",
        "    assert isinstance(refs, list) and isinstance(\n",
        "        preds, list\n",
        "    ), \"refs and preds must be lists.\"\n",
        "    tokenizer = MecabTokenizer()\n",
        "    rouge_types = [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
        "    # mecab-based rouge\n",
        "    scorer = rouge_scorer.RougeScorer(\n",
        "        rouge_types,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    # Accumulate confidence intervals.\n",
        "    aggregator = scoring.BootstrapAggregator()\n",
        "    for ref, pred in zip(refs, preds):\n",
        "        aggregator.add_scores(scorer.score(ref, pred))\n",
        "    result = aggregator.aggregate()\n",
        "    return {type: result[type].mid.fmeasure * 100 for type in rouge_types}\n",
        "\n",
        "\n",
        "class RougeLScorer(Scorer):\n",
        "    @staticmethod\n",
        "    def score(refs: list[str], preds: list[str]) -> list[float]:\n",
        "        futures: list[Future[dict[str, float]]] = []\n",
        "        with ProcessPoolExecutor() as executor:\n",
        "            for ref, pred in zip(refs, preds):\n",
        "                future = executor.submit(rouge_ja, [ref], [pred])\n",
        "                futures.append(future)\n",
        "        scores = [f.result()[\"rougeL\"] for f in futures]\n",
        "        return scores\n",
        "\n",
        "    @staticmethod\n",
        "    def aggregate(scores: list[float]) -> AggregateOutput:\n",
        "        mean = sum(scores) / len(scores)\n",
        "        return AggregateOutput(mean, {\"rougel\": mean})"
      ],
      "metadata": {
        "id": "Ga8rZaYdRaBy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScorerRegistry:\n",
        "    \"\"\"Registry to map metrics to their corresponding scorer classes.\"\"\"\n",
        "\n",
        "    _scorers: dict[str, Callable[[ScorerConfig], Scorer]] = {\n",
        "        \"rougel\": RougeLScorer,\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def get_metric_list(cls) -> list[str]:\n",
        "        \"\"\"Get a list of supported metrics.\"\"\"\n",
        "        return list(cls._scorers.keys())\n",
        "\n",
        "    @classmethod\n",
        "    def load_scorer(\n",
        "        cls, metric: str, scorer_config: ScorerConfig = ScorerConfig()\n",
        "    ) -> Scorer:\n",
        "        \"\"\"Load a scorer instance from the scorer registry.\"\"\"\n",
        "        try:\n",
        "            return cls._scorers[metric](scorer_config)  # type: ignore\n",
        "        except KeyError:\n",
        "            raise ValueError(f\"Metric '{metric}' is not supported.\")"
      ],
      "metadata": {
        "id": "sM0QHxGLRgW-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **GemmaWrapper**"
      ],
      "metadata": {
        "id": "-HSjbxhARipV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. GemmaVLMWrapper クラス: マージ済みモデルをロードして generate() を実装\n",
        "class GemmaVLMWrapper:\n",
        "    def __init__(self, model_dir: str):\n",
        "        self.model = AutoModelForImageTextToText.from_pretrained(\n",
        "            model_dir,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        self.processor = AutoProcessor.from_pretrained(model_dir, use_fast=True)\n",
        "\n",
        "    def generate(self, images: list[Image.Image], text: str, max_new_tokens: int = 50) -> str:\n",
        "        \"\"\"\n",
        "        images: PIL.Image のリスト。必ず1枚以上の画像が渡されることを前提とします。\n",
        "        text: 入力テキスト（質問文など）。\n",
        "        max_new_tokens: 生成する最大トークン数。\n",
        "        \"\"\"\n",
        "        # チャット形式で入力プロンプトを作成します。\n",
        "        # collate_fn の中と同様に、ユーザー発話で画像とテキストを組み合わせたメッセージリストを作ります。\n",
        "        messages = [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"image\", \"image\": img} for img in images] +\n",
        "                       [{\"type\": \"text\", \"text\": text}]\n",
        "        }]\n",
        "        # ここでチャットテンプレートを適用し、画像トークンが含まれるプロンプト文字列を生成します。\n",
        "        prompt = self.processor.apply_chat_template(messages, add_generation_prompt=False, tokenize=False)\n",
        "\n",
        "        # processor に渡す際は、画像はもともとリストのまま（さらにリストでラップ）にする必要があります。\n",
        "        inputs = self.processor(\n",
        "            text=[prompt],\n",
        "            images=[images],\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True\n",
        "        )\n",
        "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_ids = self.model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "        return self.processor.tokenizer.decode(output_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "ZTnKmmJ-BSsq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = TaskRegistry.load_task(\"japanese-heron-bench\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn-U3Rv3RtxC",
        "outputId": "99b719f4-987e-48f4-d86b-7eb952595f0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemmaモデルのラッパーを初期化（保存済みマージ済みモデルのディレクトリ）\n",
        "model_dir = \"google/gemma-3-4b-it\"\n",
        "model = GemmaVLMWrapper(model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fa78d6f6fdc74e2b8d8b8362192fc8a3",
            "5b6232b6e0994e15a56e04d4b453753b",
            "4dd8e8773a934e17966a43608dd37255",
            "4a731ae8ae104a509202384da55025b2",
            "af399a4fa93b40498987441dd38bdc07",
            "48531e2ec10545098f78d495b5c83d90",
            "bdc517f4fc604627a31115793e4fdcee",
            "3d8a56a64f9848d59bc2965c68d01c78",
            "26ee24c8c0354223bf3ac09dcc9cb95c",
            "60e1a655a50f4ffe96da88900bfff2b4",
            "91260905cd6e4a32bcb481acd6a31f08"
          ]
        },
        "id": "Oe3iIc_3Ry2R",
        "outputId": "33b51fcd-0879-4f4e-e49e-b8120ede7fe3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa78d6f6fdc74e2b8d8b8362192fc8a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価用に全サンプルから予測と正解をリストに収集する\n",
        "references = []\n",
        "predictions = []\n",
        "\n",
        "# 2. タスクのすべてのサンプルをループ処理する\n",
        "for example in task.dataset:\n",
        "    # 各サンプルから入力テキスト、視覚入力、正解回答を取得\n",
        "    input_text = task.doc_to_text(example)\n",
        "    image = task.doc_to_visual(\n",
        "        example\n",
        "    )  # images は list[Image.Image] として返される前提\n",
        "    reference = task.doc_to_answer(example)\n",
        "\n",
        "    # モデルから予測を生成\n",
        "    pred = model.generate(image, input_text)\n",
        "\n",
        "    # 予測と正解をリストに追加\n",
        "    predictions.append(pred)\n",
        "    references.append(reference)"
      ],
      "metadata": {
        "id": "wkW92FhdR0o3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. スコアラーで評価を行う\n",
        "scorer = ScorerRegistry.load_scorer(\"rougel\", ScorerConfig(docs=task.dataset))\n",
        "scores = scorer.score(references, predictions)\n",
        "result = scorer.aggregate(scores)\n",
        "print(\"Evaluation result:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH_afSeFR1Z0",
        "outputId": "e312332d-8359-4519-9781-a2749b8eb89c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation result: AggregateOutput(overall_score=np.float64(29.086823873934478), details={'rougel': np.float64(29.086823873934478)})\n"
          ]
        }
      ]
    }
  ]
}