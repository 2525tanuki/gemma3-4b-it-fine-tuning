{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d73764349f3343f2b28c9f5b1f5d54ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfcfce5384684c6a871da7c0d5410d8f",
              "IPY_MODEL_bb23fb5432b74f8f8df64acf3622e05e",
              "IPY_MODEL_be16353e4822472fbfbab5ff8174c0aa"
            ],
            "layout": "IPY_MODEL_2336397ef4ef431b91233a909630945a"
          }
        },
        "cfcfce5384684c6a871da7c0d5410d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717f6ec3109b41caa9d37ef21942ef41",
            "placeholder": "​",
            "style": "IPY_MODEL_61f91690f20f46d2bc3ec4dbd5ab6d75",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bb23fb5432b74f8f8df64acf3622e05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1c5794d84f47fe9a7388163d576ee9",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45171588282644f18dfca919655370d0",
            "value": 6
          }
        },
        "be16353e4822472fbfbab5ff8174c0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afb66e31ada34956b8851b391f1287dd",
            "placeholder": "​",
            "style": "IPY_MODEL_94707004eeda44e7bda3e5465ad61585",
            "value": " 6/6 [00:08&lt;00:00,  1.36s/it]"
          }
        },
        "2336397ef4ef431b91233a909630945a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717f6ec3109b41caa9d37ef21942ef41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f91690f20f46d2bc3ec4dbd5ab6d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c1c5794d84f47fe9a7388163d576ee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45171588282644f18dfca919655370d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afb66e31ada34956b8851b391f1287dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94707004eeda44e7bda3e5465ad61585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OftFv6nDGZ6p",
        "outputId": "f270ae1f-3d3e-4a02-e256-53ffed1aff71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import abc\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from datasets import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TaskConfig:\n",
        "    max_dataset_len: int | None = None\n",
        "    rotate_choices: bool = False\n",
        "\n",
        "\n",
        "class Task(abc.ABC):\n",
        "    def __init__(self, config: TaskConfig):\n",
        "        self.config = config\n",
        "\n",
        "        if self.config.max_dataset_len is not None:\n",
        "            self.dataset = self._prepare_dataset().select(\n",
        "                range(self.config.max_dataset_len)\n",
        "            )\n",
        "        else:\n",
        "            self.dataset = self._prepare_dataset()\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _prepare_dataset(self) -> Dataset:\n",
        "        \"\"\"Prepares the dataset.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def doc_to_text(self, doc) -> str:\n",
        "        \"\"\"Converts a document to text.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def doc_to_visual(self, doc) -> list[Image.Image]:\n",
        "        \"\"\"Converts a document to visual.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def doc_to_id(self, doc) -> str:\n",
        "        \"\"\"Converts a document to id.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def doc_to_answer(self, doc) -> str:\n",
        "        \"\"\"Converts a document to answer.\"\"\"\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "oXGvbsaiGgji"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset"
      ],
      "metadata": {
        "id": "p3tQG8pnGzmC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JapaneseHeronBench(Task):\n",
        "    default_metric = \"heron-bench\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _prepare_dataset() -> Dataset:\n",
        "        ds = load_dataset(\"Silviase/Japanese-Heron-Bench\", split=\"train\")\n",
        "        ds = ds.rename_column(\"text\", \"input_text\")\n",
        "        return ds\n",
        "\n",
        "    @staticmethod\n",
        "    def doc_to_text(doc) -> str:\n",
        "        return doc[\"input_text\"]\n",
        "\n",
        "    @staticmethod\n",
        "    def doc_to_visual(doc) -> list[Image.Image]:\n",
        "        return [doc[\"image\"]]\n",
        "\n",
        "    @staticmethod\n",
        "    def doc_to_id(doc) -> str:\n",
        "        return str(doc[\"question_id\"])\n",
        "\n",
        "    @staticmethod\n",
        "    def doc_to_answer(doc) -> str:\n",
        "        return doc[\"answer\"][\"gpt-4-0125-preview\"]"
      ],
      "metadata": {
        "id": "epR7YQUSGwhb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "\n",
        "\n",
        "class TaskRegistry:\n",
        "    \"\"\"Registry to map metrics to their corresponding scorer classes.\"\"\"\n",
        "\n",
        "    _tasks: dict[str, Callable[[TaskConfig], Task]] = {\n",
        "        \"japanese-heron-bench\": JapaneseHeronBench,\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def get_task_list(cls):\n",
        "        return list(cls._tasks.keys())\n",
        "\n",
        "    @classmethod\n",
        "    def load_task(cls, task_name: str, task_config: TaskConfig = TaskConfig()) -> Task:\n",
        "        try:\n",
        "            return cls._tasks[task_name](task_config)  # type: ignore\n",
        "        except KeyError:\n",
        "            raise ValueError(f\"Task '{task_name}' is not supported.\")"
      ],
      "metadata": {
        "id": "a6bC3jiuGmSH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AggregateOutput:\n",
        "    overall_score: float\n",
        "    details: dict[str, float]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ScorerConfig:\n",
        "    docs: dict | None = None\n",
        "    judge_model: str | None = None\n",
        "    batch_size: int = 10\n",
        "    random_choice: bool = False\n",
        "\n",
        "\n",
        "class Scorer(ABC):\n",
        "    def __init__(self, config: ScorerConfig):\n",
        "        self.config = config\n",
        "\n",
        "    @abstractmethod\n",
        "    def score(self, refs: list[str], preds: list[str]) -> list:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def aggregate(self, scores: list) -> AggregateOutput:\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "IaRCTUhOGtjo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AggregateOutput:\n",
        "    overall_score: float\n",
        "    details: dict[str, float]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ScorerConfig:\n",
        "    docs: dict | None = None\n",
        "    judge_model: str | None = None\n",
        "    batch_size: int = 10\n",
        "    random_choice: bool = False\n",
        "\n",
        "\n",
        "class Scorer(ABC):\n",
        "    def __init__(self, config: ScorerConfig):\n",
        "        self.config = config\n",
        "\n",
        "    @abstractmethod\n",
        "    def score(self, refs: list[str], preds: list[str]) -> list:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def aggregate(self, scores: list) -> AggregateOutput:\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "TgZNar_TIkEr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "def parse_score(llm_output: str) -> dict[str, int]:\n",
        "    json_pattern = \"r\"\n",
        "\n",
        "    if not matches:\n",
        "        json_pattern = r\"\\{.*?\\}\"\n",
        "        matches = re.findall(json_pattern, llm_output, re.DOTALL)\n",
        "\n",
        "    for json_string in matches:\n",
        "        json_string = json_string.strip()\n",
        "        try:\n",
        "            parsed_json = json.loads(json_string)\n",
        "            if (\n",
        "                isinstance(parsed_json, dict)\n",
        "                and \"score\" in parsed_json\n",
        "                and \"score_gpt\" in parsed_json\n",
        "            ):\n",
        "                return {\n",
        "                    \"score\": int(parsed_json[\"score\"]),\n",
        "                    \"score_gpt\": int(parsed_json[\"score_gpt\"]),\n",
        "                }\n",
        "        except json.JSONDecodeError:\n",
        "            try:\n",
        "                json_string_clean = re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", json_string)\n",
        "                parsed_json = json.loads(json_string_clean)\n",
        "                if (\n",
        "                    isinstance(parsed_json, dict)\n",
        "                    and \"score\" in parsed_json\n",
        "                    and \"score_gpt\" in parsed_json\n",
        "                ):\n",
        "                    return {\n",
        "                        \"score\": int(parsed_json[\"score\"]),\n",
        "                        \"score_gpt\": int(parsed_json[\"score_gpt\"]),\n",
        "                    }\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "    return {\"score\": -1, \"score_gpt\": -1}\n",
        "\n",
        "\n",
        "INSTRUCTION = \"\"\"\n",
        "You are an expert evaluator. You are given the following information:\n",
        "- Context: A description of the image.\n",
        "- Question: A question about the image.\n",
        "- GPT-4o Answer: GPT-4o's answer to the question.\n",
        "- Model Answer: The target model's answer to the question.\n",
        "\n",
        "Your task is to evaluate each answer independently based on how well it answers the question given the context.\n",
        "\n",
        "Please assign a score from 1 to 10 for each answer according to the following guideline:\n",
        "- 10: Perfect — Completely correct, relevant, and fully addresses the question based on the context.\n",
        "- 8-9: Very Good — Mostly correct with only minor inaccuracies or slight omissions.\n",
        "- 6-7: Good — Generally correct but contains noticeable errors or lacks important details.\n",
        "- 4-5: Poor — Significant errors or missing key points, but some relevance remains.\n",
        "- 1-3: Very Poor — Mostly or completely incorrect, irrelevant, or nonsensical.\n",
        "\n",
        "Output Format (JSON):\n",
        "Return the result in the following JSON format:\n",
        "```json\n",
        "{{\n",
        "    \"score_gpt\": int,\n",
        "    \"score\": int\n",
        "}}\n",
        "```\n",
        "Do not output anything other than the JSON.\n",
        "\n",
        "Input:\n",
        "{{\n",
        "    \"context\": {context},\n",
        "    \"question\": {question},\n",
        "    \"gpt4o_answer\": {gpt4o_answer},\n",
        "    \"model_answer\": {model_answer}\n",
        "}}\n",
        "\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "class HeronBenchScorer(Scorer):\n",
        "    def score(self, refs, preds: list[str]) -> list[dict[str, int]]:\n",
        "        docs = self.config.docs\n",
        "        assert docs is not None\n",
        "        assert self.config.client is not None\n",
        "        assert self.config.judge_model is not None\n",
        "\n",
        "        contents = [\n",
        "            INSTRUCTION.format(\n",
        "                context=doc[\"context\"],\n",
        "                question=doc[\"input_text\"],\n",
        "                gpt4o_answer=ref,\n",
        "                model_answer=pred,\n",
        "            )\n",
        "            for doc, ref, pred in zip(docs, refs, preds)\n",
        "        ]\n",
        "\n",
        "        completions: list[str] = ask_gpt4_batch(\n",
        "            contents, 1024, self.config.client, self.config.judge_model\n",
        "        )\n",
        "\n",
        "        scores: list[dict[str, nt]] = [parse_score(c) for c in completions]\n",
        "        return scores\n",
        "\n",
        "    def aggregate(self, scores: list[dict[str, int]]) -> AggregateOutput:\n",
        "        docs = self.config.docs\n",
        "        assert docs is not None\n",
        "        category_list = [\"conv\", \"detail\", \"complex\"]\n",
        "        heron_metrics = defaultdict(float)\n",
        "        for category in category_list:\n",
        "            score_owns = [\n",
        "                score[\"score\"]\n",
        "                for score, doc in zip(scores, docs)\n",
        "                if doc[\"category\"] == category\n",
        "            ]\n",
        "            score_gpts = [\n",
        "                score[\"score_gpt\"]\n",
        "                for score, doc in zip(scores, docs)\n",
        "                if doc[\"category\"] == category\n",
        "            ]\n",
        "            if len(score_owns) == 0 or np.mean(score_owns) == -1:\n",
        "                continue\n",
        "            avg_score = np.mean(score_owns)\n",
        "            avs_score_rel = (\n",
        "                100\n",
        "                * np.mean(score_owns)\n",
        "                / max(\n",
        "                    0.01, np.mean(score_gpts)\n",
        "                )  # divide by 0.01 when 0 division happens\n",
        "            )\n",
        "            heron_metrics[category] = avg_score\n",
        "            heron_metrics[category + \"_rel\"] = avs_score_rel\n",
        "        heron_metrics[\"parse_error_count\"] = sum(\n",
        "            score[\"score\"] == -1 for score in scores\n",
        "        )\n",
        "        heron_metrics[\"overall\"] = sum([score[\"score\"] for score in scores]) / len(\n",
        "            scores\n",
        "        )\n",
        "        heron_metrics[\"overall_rel\"] = sum(\n",
        "            [heron_metrics[category + \"_rel\"] for category in category_list]\n",
        "        ) / len(category_list)\n",
        "        output = AggregateOutput(\n",
        "            overall_score=heron_metrics[\"overall_rel\"],\n",
        "            details=heron_metrics,\n",
        "        )\n",
        "        return output"
      ],
      "metadata": {
        "id": "Lj9M2QoTIbTf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "\n",
        "\n",
        "class ScorerRegistry:\n",
        "    \"\"\"Registry to map metrics to their corresponding scorer classes.\"\"\"\n",
        "\n",
        "    _scorers: dict[str, Callable[[ScorerConfig], Scorer]] = {\n",
        "        \"heron-bench\": HeronBenchScorer,\n",
        "        \"rougel\": RougeLScorer,\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def get_metric_list(cls) -> list[str]:\n",
        "        \"\"\"Get a list of supported metrics.\"\"\"\n",
        "        return list(cls._scorers.keys())\n",
        "\n",
        "    @classmethod\n",
        "    def load_scorer(\n",
        "        cls, metric: str, scorer_config: ScorerConfig = ScorerConfig()\n",
        "    ) -> Scorer:\n",
        "        \"\"\"Load a scorer instance from the scorer registry.\"\"\"\n",
        "        try:\n",
        "            return cls._scorers[metric](scorer_config)  # type: ignore\n",
        "        except KeyError:\n",
        "            raise ValueError(f\"Metric '{metric}' is not supported.\")"
      ],
      "metadata": {
        "id": "cmGynDpJHCpC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fugashi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7y-CrbQPXh5",
        "outputId": "aad1cce1-4b70-4876-edb2-5639c693ab70"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.11/dist-packages (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY7LFPwKPf4B",
        "outputId": "1506713f-c78a-4d5b-d5b3-51a20ca86919"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from rouge_score import rouge_scorer, scoring\n",
        "from fugashi import Tagger\n",
        "import unicodedata\n",
        "from concurrent.futures import ProcessPoolExecutor, Future"
      ],
      "metadata": {
        "id": "ES00T2uOPJIC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RougeLScorer(Scorer):\n",
        "    @staticmethod\n",
        "    def score(refs: list[str], preds: list[str]) -> list[float]:\n",
        "        futures: list[Future[dict[str, float]]] = []\n",
        "        with ProcessPoolExecutor() as executor:\n",
        "            for ref, pred in zip(refs, preds):\n",
        "                future = executor.submit(rouge_ja, [ref], [pred])\n",
        "                futures.append(future)\n",
        "        scores = [f.result()[\"rougeL\"] for f in futures]\n",
        "        return scores\n",
        "\n",
        "    @staticmethod\n",
        "    def aggregate(scores: list[float]) -> AggregateOutput:\n",
        "        mean = sum(scores) / len(scores)\n",
        "        return AggregateOutput(mean, {\"rougel\": mean})"
      ],
      "metadata": {
        "id": "6ScDffWmLCxq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def rouge_ja(refs: list[str], preds: list[str]) -> dict:\n",
        "    \"\"\"Compute ROUGE-L scores for Japanese text.\n",
        "    Args:\n",
        "        refs: list of reference strings\n",
        "        preds: list of predicted strings\n",
        "    Returns:\n",
        "        dict: dictionary with keys: { 'rouge1', 'rouge2', 'rougeL' }\n",
        "        Each value is a float representing the ROUGE score (f-measure) * 100.\n",
        "    \"\"\"\n",
        "    assert isinstance(refs, list) and isinstance(\n",
        "        preds, list\n",
        "    ), \"refs and preds must be lists.\"\n",
        "    tokenizer = MecabTokenizer()\n",
        "    rouge_types = [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
        "    # mecab-based rouge\n",
        "    scorer = rouge_scorer.RougeScorer(\n",
        "        rouge_types,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    # Accumulate confidence intervals.\n",
        "    aggregator = scoring.BootstrapAggregator()\n",
        "    for ref, pred in zip(refs, preds):\n",
        "        aggregator.add_scores(scorer.score(ref, pred))\n",
        "    result = aggregator.aggregate()\n",
        "    return {type: result[type].mid.fmeasure * 100 for type in rouge_types}"
      ],
      "metadata": {
        "id": "f6ZCDQkcQ7tS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MecabTokenizer:\n",
        "    def __init__(self) -> None:\n",
        "        self.tagger = Tagger(\"-Owakati\")\n",
        "\n",
        "    def normalize_answer(self, text: str) -> str:\n",
        "        \"\"\"Lower case text, remove punctuation and extra whitespace, etc.\"\"\"\n",
        "\n",
        "        def white_space_fix(text: str) -> str:\n",
        "            return \" \".join(text.split())\n",
        "\n",
        "        def remove_emoji(text: str) -> str:\n",
        "            text = \"\".join([\"\" if emoji.is_emoji(c) else c for c in text])\n",
        "            emoji_pattern = re.compile(\n",
        "                \"[\"\n",
        "                \"\\U0001f600-\\U0001f64f\"  # emoticons\n",
        "                \"\\U0001f300-\\U0001f5ff\"  # symbols & pictographs\n",
        "                \"\\U0001f680-\\U0001f6ff\"  # transport & map symbols\n",
        "                \"\\U0001f1e0-\\U0001f1ff\"  # flags (iOS)\n",
        "                \"\\U00002702-\\U000027b0\"\n",
        "                \"]+\",\n",
        "                flags=re.UNICODE,\n",
        "            )\n",
        "            return emoji_pattern.sub(r\"\", text)\n",
        "\n",
        "        text = remove_emoji(text)\n",
        "        # see neologdn docs for details, but handles things like full/half width variation\n",
        "        # text = neologdn.normalize(text) FIXME: fix c++12 error when installing neologdn\n",
        "        text = unicodedata.normalize(\"NFKC\", text)\n",
        "        text = white_space_fix(text)\n",
        "        return text\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return self.tagger.parse(self.normalize_answer(text)).split()\n"
      ],
      "metadata": {
        "id": "uDfjpTSYQ_EG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidic-lite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkeTIRuARgYp",
        "outputId": "6c0acbe6-e71b-46b9-eaf9-a0adb8b7accb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidic-lite in /usr/local/lib/python3.11/dist-packages (1.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m unidic download"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21vHw2jxRzf3",
        "outputId": "79214bb4-29ee-4bec-c727-5fba3299b154"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: No module named unidic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE6cLwCgR-0a",
        "outputId": "0c778d3a-bd7d-4899-d42c-f5102697d0b0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji"
      ],
      "metadata": {
        "id": "TmbhtJ18SEUq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここまでがllm-jp-eval-mmの必要な部分を動くように変更したもの"
      ],
      "metadata": {
        "id": "CIqXIw1wS6u3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここからが評価"
      ],
      "metadata": {
        "id": "xiIvBxsxS6rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from transformers import AutoModelForImageTextToText, AutoProcessor\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "\n",
        "# 1. GemmaVLMWrapper クラス: マージ済みモデルをロードして generate() を実装\n",
        "class GemmaVLMWrapper:\n",
        "    def __init__(self, model_dir: str):\n",
        "        self.model = AutoModelForImageTextToText.from_pretrained(\n",
        "            model_dir, torch_dtype=torch.bfloat16, device_map=\"auto\"\n",
        "        )\n",
        "        self.processor = AutoProcessor.from_pretrained(model_dir, use_fast=True)\n",
        "\n",
        "    def generate(\n",
        "        self, images: list[Image.Image], text: str, max_new_tokens: int = 50\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        images: PIL.Image のリスト。必ず1枚以上の画像が渡されることを前提とします。\n",
        "        text: 入力テキスト（質問文など）。\n",
        "        max_new_tokens: 生成する最大トークン数。\n",
        "        \"\"\"\n",
        "        # チャット形式で入力プロンプトを作成します。\n",
        "        # collate_fn の中と同様に、ユーザー発話で画像とテキストを組み合わせたメッセージリストを作ります。\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [{\"type\": \"image\", \"image\": img} for img in images]\n",
        "                + [{\"type\": \"text\", \"text\": text}],\n",
        "            }\n",
        "        ]\n",
        "        # ここでチャットテンプレートを適用し、画像トークンが含まれるプロンプト文字列を生成します。\n",
        "        prompt = self.processor.apply_chat_template(\n",
        "            messages, add_generation_prompt=False, tokenize=False\n",
        "        )\n",
        "\n",
        "        # processor に渡す際は、画像はもともとリストのまま（さらにリストでラップ）にする必要があります。\n",
        "        inputs = self.processor(\n",
        "            text=[prompt], images=[images], return_tensors=\"pt\", padding=True\n",
        "        )\n",
        "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_ids = self.model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "        return self.processor.tokenizer.decode(output_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "nZoyfUlgS5xa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = TaskRegistry.load_task(\"japanese-heron-bench\")\n",
        "\n",
        "# 評価用に全サンプルから予測と正解をリストに収集する\n",
        "references = []\n",
        "predictions = []\n",
        "\n",
        "# Gemmaモデルのラッパーを初期化（保存済みマージ済みモデルのディレクトリ）\n",
        "model_dir = \"/content/drive/MyDrive/gemma3-jicvqa-finetuned\"\n",
        "model = GemmaVLMWrapper(model_dir)\n",
        "\n",
        "# 2. タスクのすべてのサンプルをループ処理する\n",
        "for example in task.dataset:\n",
        "    # 各サンプルから入力テキスト、視覚入力、正解回答を取得\n",
        "    input_text = task.doc_to_text(example)\n",
        "    images = task.doc_to_visual(\n",
        "        example\n",
        "    )  # images は list[Image.Image] として返される前提\n",
        "    reference = task.doc_to_answer(example)\n",
        "\n",
        "    # モデルから予測を生成\n",
        "    pred = model.generate(images, input_text)\n",
        "\n",
        "    # 予測と正解をリストに追加\n",
        "    predictions.append(pred)\n",
        "    references.append(reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "d73764349f3343f2b28c9f5b1f5d54ae",
            "cfcfce5384684c6a871da7c0d5410d8f",
            "bb23fb5432b74f8f8df64acf3622e05e",
            "be16353e4822472fbfbab5ff8174c0aa",
            "2336397ef4ef431b91233a909630945a",
            "717f6ec3109b41caa9d37ef21942ef41",
            "61f91690f20f46d2bc3ec4dbd5ab6d75",
            "5c1c5794d84f47fe9a7388163d576ee9",
            "45171588282644f18dfca919655370d0",
            "afb66e31ada34956b8851b391f1287dd",
            "94707004eeda44e7bda3e5465ad61585"
          ]
        },
        "id": "WP8xRGP2SpQ-",
        "outputId": "1b3ef8a6-7707-4db5-ea0a-19ede8e1d859"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d73764349f3343f2b28c9f5b1f5d54ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation result: AggregateOutput(overall_score=np.float64(31.956091217206772), details={'rougel': np.float64(31.956091217206772)})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. スコアラーで評価を行う\n",
        "scorer = ScorerRegistry.load_scorer(\"rougel\", ScorerConfig(docs=task.dataset))\n",
        "scores = scorer.score(references, predictions)\n",
        "result = scorer.aggregate(scores)\n",
        "print(\"Evaluation result:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTGZNzZBJW0w",
        "outputId": "2c5d6ba4-56ac-43ba-d33e-b905c558734b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation result: AggregateOutput(overall_score=np.float64(31.956091217206772), details={'rougel': np.float64(31.956091217206772)})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CRyvqSK6PopP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}